import os
import jq
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import JSONLoader
from langchain_community.vectorstores import Chroma
# Ollamaé–¢é€£ã®ã‚¯ãƒ©ã‚¹ã‚’æ–°ã—ã„`langchain-ollama`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain.chains import RetrievalQA

# --- å®šæ•°å®šç¾© ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã‹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "nomic-embed-text:latest")
LLM_MODEL = os.getenv("LLM_MODEL", "llama3:latest")
CHROMA_DB_PATH = "./chroma_db"
DATA_PATH = "./data/scraped_data.json"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

class RAGHandler:
    """
    RAG (Retrieval-Augmented Generation) ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã€QAãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ã¨å®Ÿè¡Œã‚’æ‹…å½“ã™ã‚‹ã€‚
    """
    def __init__(self):
        """
        RAGHandlerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
        """
        self.vector_store = None
        self.qa_chain = None
        self._initialize()

    def _initialize(self):
        """
        ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨QAãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–å‡¦ç†ã‚’è¡Œã†ã€‚
        - æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿ã€ãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ–°è¦ä½œæˆã™ã‚‹ã€‚
        - LLMã¨ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’çµ„ã¿åˆã‚ã›ãŸQAãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
        """
        # 1. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)

        # 2. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯ä½œæˆ
        if os.path.exists(CHROMA_DB_PATH) and os.listdir(CHROMA_DB_PATH):
            print("âœ… Loading existing vector store...")
            self.vector_store = Chroma(
                persist_directory=CHROMA_DB_PATH, 
                embedding_function=embeddings
            )
        else:
            print("â³ Creating new vector store...")
            if not os.path.exists(DATA_PATH):
                raise FileNotFoundError(
                    f"'{DATA_PATH}' not found. Please run scraper.py to generate the data file."
                )
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€
            loader = JSONLoader(
                file_path=DATA_PATH,
                jq_schema='.[] | .content', # JSONé…åˆ—ã‹ã‚‰å„è¦ç´ ã®'content'ã‚­ãƒ¼ã‚’æŠ½å‡º
                text_content=True,
                json_lines=False 
            )
            documents = loader.load()
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ï¼ˆå°ã•ãªæ–­ç‰‡ï¼‰ã«åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=CHUNK_SIZE, 
                chunk_overlap=CHUNK_OVERLAP
            )
            docs = text_splitter.split_documents(documents)
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ChromaDBã«ä¿å­˜
            self.vector_store = Chroma.from_documents(
                documents=docs, 
                embedding=embeddings,
                persist_directory=CHROMA_DB_PATH
            )
            print(f"âœ… Vector store created with {len(docs)} document chunks.")
        
        # 3. å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®åˆæœŸåŒ–
        llm = ChatOllama(model=LLM_MODEL)
        
        # 4. QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff", # å–å¾—ã—ãŸæ–‡æ›¸ã‚’ã™ã¹ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™æ–¹å¼
            retriever=self.vector_store.as_retriever(),
            return_source_documents=True # å›ç­”ã®æ ¹æ‹ ã¨ãªã£ãŸã‚½ãƒ¼ã‚¹æ–‡æ›¸ã‚‚è¿”ã™è¨­å®š
        )
        print("ğŸš€ RAG Handler is ready.")

    def ask(self, query: str):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã‚’å—ã‘å–ã‚Šã€QAãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        
        Args:
            query (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ãƒ†ã‚­ã‚¹ãƒˆã€‚

        Returns:
            dict: å›ç­”ã¨ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å«ã‚€è¾æ›¸ã€‚
        """
        if self.qa_chain is None:
            print("âŒ QA chain is not initialized.")
            return {"error": "QA chain is not initialized."}
        
        try:
            print(f"ğŸ”„ Processing query: {query}")
            response = self.qa_chain.invoke({"query": query})
            
            # ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            sources = []
            if "source_documents" in response:
                for doc in response["source_documents"]:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚Œã°URLã‚’å–å¾—ã€ãªã‘ã‚Œã°'Unknown'
                    url = doc.metadata.get('source', 'Unknown')
                    sources.append(url)
            
            print("âœ… Answer generated.")
            return {
                "answer": response.get("result"),
                # é‡è¤‡ã‚’é™¤ã„ãŸã‚½ãƒ¼ã‚¹URLã®ãƒªã‚¹ãƒˆ
                "source_documents": list(set(sources))
            }
        except Exception as e:
            print(f"ğŸ”¥ Error during QA chain invocation: {e}")
            return {"error": "Failed to get an answer from the QA chain."}

# --- ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ ---
# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§RAGHandlerã®å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å…±æœ‰ã™ã‚‹ãŸã‚ã«ã€
# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚
rag_handler_instance = RAGHandler()
